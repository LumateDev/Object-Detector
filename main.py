#!/usr/bin/env python3
"""
Object Detector v1.0
–î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ (—á–µ–ª–æ–≤–µ–∫, —á–∞—à–∫–∞, —Ç–µ–ª–µ—Ñ–æ–Ω) –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
—Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤–µ–±-–∫–∞–º–µ—Ä—ã –∏ YOLOv8
"""

import cv2
import numpy as np
import time
import os
import sys
import argparse
from datetime import datetime
from pathlib import Path
from collections import deque
from typing import Optional, Dict, List, Tuple, Any

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ —É—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
def check_dependencies():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –±–∏–±–ª–∏–æ—Ç–µ–∫"""
    missing = []
    
    try:
        import ultralytics
    except ImportError:
        missing.append('ultralytics')
    
    try:
        import cv2
    except ImportError:
        missing.append('opencv-python')
    
    try:
        import numpy
    except ImportError:
        missing.append('numpy')
    
    try:
        import yaml
    except ImportError:
        missing.append('PyYAML')
    
    if missing:
        print(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –±–∏–±–ª–∏–æ—Ç–µ–∫–∏: {', '.join(missing)}")
        print(f"   –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∏—Ö –∫–æ–º–∞–Ω–¥–æ–π: pip install {' '.join(missing)}")
        sys.exit(1)

check_dependencies()

from ultralytics import YOLO
import yaml


class Colors:
    """–¶–≤–µ—Ç–æ–≤–∞—è —Å—Ö–µ–º–∞ –¥–ª—è –∫–ª–∞—Å—Å–æ–≤ –æ–±—ä–µ–∫—Ç–æ–≤"""
    # BGR —Ñ–æ—Ä–º–∞—Ç –¥–ª—è OpenCV
    PERSON = (0, 255, 0)      # –ó–µ–ª—ë–Ω—ã–π
    CUP = (255, 150, 0)       # –°–∏–Ω–∏–π
    PHONE = (0, 165, 255)     # –û—Ä–∞–Ω–∂–µ–≤—ã–π
    
    # –¶–≤–µ—Ç–∞ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
    TEXT_BG = (0, 0, 0)       # –ß—ë—Ä–Ω—ã–π —Ñ–æ–Ω
    TEXT_FG = (255, 255, 255) # –ë–µ–ª—ã–π —Ç–µ–∫—Å—Ç
    STATS_BG = (40, 40, 40)   # –¢—ë–º–Ω–æ-—Å–µ—Ä—ã–π
    
    @classmethod
    def get_color(cls, class_id: int) -> Tuple[int, int, int]:
        """–ü–æ–ª—É—á–∏—Ç—å —Ü–≤–µ—Ç –ø–æ ID –∫–ª–∞—Å—Å–∞"""
        color_map = {
            0: cls.PERSON,   # person
            41: cls.CUP,     # cup
            67: cls.PHONE    # cell phone
        }
        return color_map.get(class_id, (128, 128, 128))


class FPSCounter:
    """–°—á—ë—Ç—á–∏–∫ FPS —Å —É—Å—Ä–µ–¥–Ω–µ–Ω–∏–µ–º"""
    
    def __init__(self, avg_frames: int = 30):
        self.times = deque(maxlen=avg_frames)
        self.last_time = time.time()
    
    def update(self) -> float:
        """–û–±–Ω–æ–≤–∏—Ç—å –∏ –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â–∏–π FPS"""
        current_time = time.time()
        self.times.append(current_time - self.last_time)
        self.last_time = current_time
        
        if len(self.times) > 0:
            return 1.0 / (sum(self.times) / len(self.times))
        return 0.0


class Config:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"""
    
    DEFAULT_CONFIG = {
        'camera': {
            'index': 0,
            'width': 640,
            'height': 480,
            'fps': 30
        },
        'detection': {
            'model': 'yolov8n.pt',
            'confidence': 0.5,
            'classes': [0, 41, 67]
        },
        'display': {
            'show_fps': True,
            'show_confidence': True,
            'show_stats': True,
            'box_thickness': 2,
            'font_scale': 0.6
        },
        'mode': 'balanced'
    }
    
    MODES = {
        'fast': {
            'camera': {'width': 320, 'height': 240},
            'detection': {'confidence': 0.4}
        },
        'balanced': {
            'camera': {'width': 640, 'height': 480},
            'detection': {'confidence': 0.5}
        },
        'accurate': {
            'camera': {'width': 1280, 'height': 720},
            'detection': {'confidence': 0.6}
        }
    }
    
    def __init__(self, config_path: Optional[str] = None, mode: Optional[str] = None):
        self.config = self.DEFAULT_CONFIG.copy()
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ —Ñ–∞–π–ª–∞
        if config_path and os.path.exists(config_path):
            self._load_from_file(config_path)
        
        # –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞
        if mode and mode in self.MODES:
            self._apply_mode(mode)
    
    def _load_from_file(self, path: str):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ –∏–∑ YAML —Ñ–∞–π–ª–∞"""
        try:
            with open(path, 'r', encoding='utf-8') as f:
                loaded = yaml.safe_load(f)
                if loaded:
                    self._deep_update(self.config, loaded)
            print(f"[INFO] –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –∏–∑ {path}")
        except Exception as e:
            print(f"[WARN] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω—Ñ–∏–≥–∞: {e}")
    
    def _deep_update(self, base: dict, update: dict):
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è"""
        for key, value in update.items():
            if key in base and isinstance(base[key], dict) and isinstance(value, dict):
                self._deep_update(base[key], value)
            else:
                base[key] = value
    
    def _apply_mode(self, mode: str):
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞"""
        if mode in self.MODES:
            self._deep_update(self.config, self.MODES[mode])
            print(f"[INFO] –ü—Ä–∏–º–µ–Ω—ë–Ω —Ä–µ–∂–∏–º: {mode}")
    
    def get(self, *keys):
        """–ü–æ–ª—É—á–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ –∫–ª—é—á–∞–º"""
        value = self.config
        for key in keys:
            value = value.get(key, {})
        return value


class ObjectDetector:
    """–û—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ –æ–±—ä–µ–∫—Ç–æ–≤"""
    
    # –ù–∞–∑–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º
    CLASS_NAMES = {
        0: '–ß–µ–ª–æ–≤–µ–∫',
        41: '–ß–∞—à–∫–∞',
        67: '–¢–µ–ª–µ—Ñ–æ–Ω'
    }
    
    def __init__(self, config: Config):
        self.config = config
        self.model: Optional[YOLO] = None
        self.cap: Optional[cv2.VideoCapture] = None
        self.fps_counter = FPSCounter()
        
        # –°–æ—Å—Ç–æ—è–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
        self.is_running = True
        self.is_paused = False
        self.show_fps = config.get('display', 'show_fps')
        self.show_confidence = config.get('display', 'show_confidence')
        self.show_stats = config.get('display', 'show_stats')
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.detection_stats: Dict[int, int] = {0: 0, 41: 0, 67: 0}
        self.last_frame: Optional[np.ndarray] = None
        
        # –ü–∞–ø–∫–∞ –¥–ª—è —Å–∫—Ä–∏–Ω—à–æ—Ç–æ–≤
        self.screenshots_dir = Path('screenshots')
        self.screenshots_dir.mkdir(exist_ok=True)
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        self.box_thickness = config.get('display', 'box_thickness')
        self.font_scale = config.get('display', 'font_scale')
        self.target_classes = config.get('detection', 'classes')
        self.confidence_threshold = config.get('detection', 'confidence')
    
    def print_banner(self):
        """–í—ã–≤–æ–¥ –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –±–∞–Ω–Ω–µ—Ä–∞"""
        banner = """
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë       üéØ Object Detector v1.0             ‚ïë
‚ïë       –î–ª—è –Ω–æ—É—Ç–±—É–∫–∞ —Å –≤–µ–±-–∫–∞–º–µ—Ä–æ–π          ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë  –î–µ—Ç–µ–∫—Ç–∏—Ä—É–µ–º—ã–µ –æ–±—ä–µ–∫—Ç—ã:                   ‚ïë
‚ïë    üü¢ –ß–µ–ª–æ–≤–µ–∫ (person)                    ‚ïë
‚ïë    üîµ –ß–∞—à–∫–∞ (cup)                         ‚ïë
‚ïë    üü† –¢–µ–ª–µ—Ñ–æ–Ω (cell phone)                ‚ïë
‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£
‚ïë  –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ:                              ‚ïë
‚ïë    –ü–†–û–ë–ï–õ  - –°—Ç–∞—Ä—Ç/–ü–∞—É–∑–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏        ‚ïë
‚ïë    S       - –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Å–∫—Ä–∏–Ω—à–æ—Ç          ‚ïë
‚ïë    F       - –ü–æ–∫–∞–∑–∞—Ç—å/—Å–∫—Ä—ã—Ç—å FPS         ‚ïë
‚ïë    C       - –ü–æ–∫–∞–∑–∞—Ç—å/—Å–∫—Ä—ã—Ç—å confidence  ‚ïë
‚ïë    I       - –ü–æ–∫–∞–∑–∞—Ç—å/—Å–∫—Ä—ã—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É  ‚ïë
‚ïë    Q / ESC - –í—ã—Ö–æ–¥                       ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
"""
        print(banner)
    
    def initialize(self) -> bool:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤"""
        print("\n[INFO] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è...")
        
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏ –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
        if not self._load_model():
            return False
        
        # 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–∞–º–µ—Ä—ã
        if not self._init_camera():
            return False
        
        # 3. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤
        self._detect_resources()
        
        print("[INFO] ‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!\n")
        return True
    
    def _load_model(self) -> bool:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ YOLO"""
        model_name = self.config.get('detection', 'model')
        print(f"[INFO] –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ {model_name}...")
        
        try:
            # –ü—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä (—ç–º—É–ª—è—Ü–∏—è)
            self._print_progress("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏", 0)
            
            self.model = YOLO(model_name)
            
            self._print_progress("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏", 100)
            print()
            
            # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏
            model_path = Path(model_name)
            if model_path.exists():
                size_mb = model_path.stat().st_size / (1024 * 1024)
                print(f"[INFO] –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ ({size_mb:.1f} MB)")
            else:
                print(f"[INFO] –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (—Å–∫–∞—á–∞–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)")
            
            return True
            
        except Exception as e:
            print(f"\n[ERROR] –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
            return False
    
    def _init_camera(self) -> bool:
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ–±-–∫–∞–º–µ—Ä—ã"""
        camera_index = self.config.get('camera', 'index')
        width = self.config.get('camera', 'width')
        height = self.config.get('camera', 'height')
        fps = self.config.get('camera', 'fps')
        
        print(f"[INFO] –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –∫–∞–º–µ—Ä–µ {camera_index}...")
        
        # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –∫–∞–º–µ—Ä–µ
        self.cap = cv2.VideoCapture(camera_index)
        
        if not self.cap.isOpened():
            # –ü–æ–ø—Ä–æ–±—É–µ–º –¥—Ä—É–≥–∏–µ –∏–Ω–¥–µ–∫—Å—ã
            for idx in range(3):
                if idx != camera_index:
                    self.cap = cv2.VideoCapture(idx)
                    if self.cap.isOpened():
                        print(f"[INFO] –ö–∞–º–µ—Ä–∞ –Ω–∞–π–¥–µ–Ω–∞ –Ω–∞ –∏–Ω–¥–µ–∫—Å–µ {idx}")
                        break
        
        if not self.cap.isOpened():
            print("[ERROR] ‚ùå –í–µ–±-–∫–∞–º–µ—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞!")
            print("        –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫–∞–º–µ—Ä—ã")
            return False
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∫–∞–º–µ—Ä—ã
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
        self.cap.set(cv2.CAP_PROP_FPS, fps)
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        actual_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        actual_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        actual_fps = int(self.cap.get(cv2.CAP_PROP_FPS))
        
        print(f"[INFO] ‚úÖ –ö–∞–º–µ—Ä–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∞: {actual_width}x{actual_height} @ {actual_fps}fps")
        
        return True
    
    def _detect_resources(self):
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤"""
        import torch
        
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            print(f"[INFO] GPU –æ–±–Ω–∞—Ä—É–∂–µ–Ω: {gpu_name}")
            print("[INFO] –†–µ–∂–∏–º: CUDA (GPU)")
        else:
            print("[INFO] GPU –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω")
            print("[INFO] –†–µ–∂–∏–º: CPU (–æ–∂–∏–¥–∞–µ–º—ã–π FPS: 10-20)")
    
    def _print_progress(self, label: str, percent: int):
        """–í—ã–≤–æ–¥ –ø—Ä–æ–≥—Ä–µ—Å—Å-–±–∞—Ä–∞"""
        bar_length = 30
        filled = int(bar_length * percent / 100)
        bar = '‚ñà' * filled + '‚ñë' * (bar_length - filled)
        print(f"\r[INFO] {label}: [{bar}] {percent}%", end='', flush=True)
    
    def detect(self, frame: np.ndarray) -> List[Dict[str, Any]]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–æ–≤"""
        results = self.model(
            frame,
            conf=self.confidence_threshold,
            classes=self.target_classes,
            verbose=False
        )
        
        detections = []
        
        for result in results:
            boxes = result.boxes
            
            if boxes is None:
                continue
            
            for i in range(len(boxes)):
                box = boxes[i]
                
                # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(int)
                
                # –ö–ª–∞—Å—Å –∏ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
                class_id = int(box.cls[0].cpu().numpy())
                confidence = float(box.conf[0].cpu().numpy())
                
                detections.append({
                    'bbox': (x1, y1, x2, y2),
                    'class_id': class_id,
                    'class_name': self.CLASS_NAMES.get(class_id, 'Unknown'),
                    'confidence': confidence
                })
        
        return detections
    
    def draw_detections(self, frame: np.ndarray, detections: List[Dict]) -> np.ndarray:
        """–û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–µ—Ç–µ–∫—Ü–∏–∏"""
        overlay = frame.copy()
        
        # –°–±—Ä–æ—Å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        self.detection_stats = {0: 0, 41: 0, 67: 0}
        
        for det in detections:
            x1, y1, x2, y2 = det['bbox']
            class_id = det['class_id']
            class_name = det['class_name']
            confidence = det['confidence']
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self.detection_stats[class_id] = self.detection_stats.get(class_id, 0) + 1
            
            # –¶–≤–µ—Ç –¥–ª—è –∫–ª–∞—Å—Å–∞
            color = Colors.get_color(class_id)
            
            # Bounding box
            cv2.rectangle(overlay, (x1, y1), (x2, y2), color, self.box_thickness)
            
            # –ü–æ–¥–ø–∏—Å—å
            if self.show_confidence:
                label = f"{class_name}: {confidence*100:.0f}%"
            else:
                label = class_name
            
            # –†–∞–∑–º–µ—Ä —Ç–µ–∫—Å—Ç–∞
            (text_width, text_height), baseline = cv2.getTextSize(
                label, cv2.FONT_HERSHEY_SIMPLEX, self.font_scale, 2
            )
            
            # –§–æ–Ω –¥–ª—è —Ç–µ–∫—Å—Ç–∞
            cv2.rectangle(
                overlay,
                (x1, y1 - text_height - 10),
                (x1 + text_width + 10, y1),
                color,
                -1
            )
            
            # –¢–µ–∫—Å—Ç
            cv2.putText(
                overlay,
                label,
                (x1 + 5, y1 - 5),
                cv2.FONT_HERSHEY_SIMPLEX,
                self.font_scale,
                Colors.TEXT_FG,
                2
            )
        
        # –°–º–µ—à–∏–≤–∞–Ω–∏–µ —Å –æ—Ä–∏–≥–∏–Ω–∞–ª–æ–º –¥–ª—è –ø–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω–æ—Å—Ç–∏
        cv2.addWeighted(overlay, 0.85, frame, 0.15, 0, frame)
        
        return frame
    
    def draw_stats(self, frame: np.ndarray, fps: float) -> np.ndarray:
        """–û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        h, w = frame.shape[:2]
        
        # –ü–∞–Ω–µ–ª—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        if self.show_stats:
            stats_height = 120
            
            # –ü–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–π —Ñ–æ–Ω
            overlay = frame.copy()
            cv2.rectangle(overlay, (10, 10), (220, stats_height), Colors.STATS_BG, -1)
            cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
            
            y_offset = 35
            
            # FPS
            if self.show_fps:
                fps_text = f"FPS: {fps:.1f}"
                cv2.putText(frame, fps_text, (20, y_offset),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, Colors.TEXT_FG, 2)
                y_offset += 25
            
            # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—ä–µ–∫—Ç–æ–≤
            total_objects = sum(self.detection_stats.values())
            cv2.putText(frame, f"–û–±—ä–µ–∫—Ç–æ–≤: {total_objects}", (20, y_offset),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, Colors.TEXT_FG, 2)
            y_offset += 25
            
            # –î–µ—Ç–∞–ª–∏ –ø–æ –∫–ª–∞—Å—Å–∞–º
            for class_id, count in self.detection_stats.items():
                if count > 0:
                    name = self.CLASS_NAMES[class_id]
                    color = Colors.get_color(class_id)
                    cv2.putText(frame, f"  {name}: {count}", (20, y_offset),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
                    y_offset += 20
        
        # –ò–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø–∞—É–∑—ã
        if self.is_paused:
            pause_text = "‚è∏ –ü–ê–£–ó–ê"
            text_size = cv2.getTextSize(pause_text, cv2.FONT_HERSHEY_SIMPLEX, 1.2, 3)[0]
            x = (w - text_size[0]) // 2
            y = h // 2
            
            # –§–æ–Ω
            cv2.rectangle(frame, (x - 20, y - 40), (x + text_size[0] + 20, y + 20),
                         Colors.TEXT_BG, -1)
            cv2.putText(frame, pause_text, (x, y),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 255, 255), 3)
        
        # –ü–æ–¥—Å–∫–∞–∑–∫–∞ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤–Ω–∏–∑—É
        help_text = "SPACE: –ü–∞—É–∑–∞ | S: –°–∫—Ä–∏–Ω—à–æ—Ç | Q: –í—ã—Ö–æ–¥"
        cv2.putText(frame, help_text, (10, h - 15),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.5, Colors.TEXT_FG, 1)
        
        return frame
    
    def save_screenshot(self, frame: np.ndarray):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–∫—Ä–∏–Ω—à–æ—Ç–∞"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = self.screenshots_dir / f"detection_{timestamp}.jpg"
        
        cv2.imwrite(str(filename), frame)
        print(f"[INFO] üì∑ –°–∫—Ä–∏–Ω—à–æ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {filename}")
    
    def handle_key(self, key: int) -> bool:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–∞–∂–∞—Ç–∏–π –∫–ª–∞–≤–∏—à"""
        if key == ord('q') or key == ord('Q') or key == 27:  # Q –∏–ª–∏ ESC
            print("\n[INFO] –í—ã—Ö–æ–¥ –∏–∑ –ø—Ä–æ–≥—Ä–∞–º–º—ã...")
            return False
        
        elif key == ord(' '):  # –ü—Ä–æ–±–µ–ª - –ø–∞—É–∑–∞
            self.is_paused = not self.is_paused
            status = "‚è∏ –ü–∞—É–∑–∞" if self.is_paused else "‚ñ∂ –ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ"
            print(f"[INFO] {status}")
        
        elif key == ord('s') or key == ord('S'):  # –°–∫—Ä–∏–Ω—à–æ—Ç
            if self.last_frame is not None:
                self.save_screenshot(self.last_frame)
        
        elif key == ord('f') or key == ord('F'):  # –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ FPS
            self.show_fps = not self.show_fps
            print(f"[INFO] FPS: {'–ø–æ–∫–∞–∑–∞–Ω' if self.show_fps else '—Å–∫—Ä—ã—Ç'}")
        
        elif key == ord('c') or key == ord('C'):  # –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ confidence
            self.show_confidence = not self.show_confidence
            print(f"[INFO] Confidence: {'–ø–æ–∫–∞–∑–∞–Ω' if self.show_confidence else '—Å–∫—Ä—ã—Ç'}")
        
        elif key == ord('i') or key == ord('I'):  # –ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
            self.show_stats = not self.show_stats
            print(f"[INFO] –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {'–ø–æ–∫–∞–∑–∞–Ω–∞' if self.show_stats else '—Å–∫—Ä—ã—Ç–∞'}")
        
        return True
    
    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª —Ä–∞–±–æ—Ç—ã"""
        self.print_banner()
        
        if not self.initialize():
            print("\n[ERROR] –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –Ω–µ —É–¥–∞–ª–∞—Å—å. –í—ã—Ö–æ–¥.")
            return
        
        print("[INFO] ‚ñ∂ –î–µ—Ç–µ–∫—Ü–∏—è –∑–∞–ø—É—â–µ–Ω–∞!")
        print("[INFO] –î–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≥–æ—Ä—è—á–∏–µ –∫–ª–∞–≤–∏—à–∏\n")
        
        window_name = "Object Detector - YOLOv8"
        cv2.namedWindow(window_name, cv2.WINDOW_NORMAL)
        
        try:
            while self.is_running:
                # –ß—Ç–µ–Ω–∏–µ –∫–∞–¥—Ä–∞
                ret, frame = self.cap.read()
                
                if not ret:
                    print("[WARN] –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∫–∞–¥—Ä —Å –∫–∞–º–µ—Ä—ã")
                    continue
                
                # –ó–µ—Ä–∫–∞–ª—å–Ω–æ–µ –æ—Ç—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
                frame = cv2.flip(frame, 1)
                
                # –î–µ—Ç–µ–∫—Ü–∏—è (–µ—Å–ª–∏ –Ω–µ –Ω–∞ –ø–∞—É–∑–µ)
                if not self.is_paused:
                    detections = self.detect(frame)
                    frame = self.draw_detections(frame, detections)
                else:
                    # –ù–∞ –ø–∞—É–∑–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–µ—Ç–µ–∫—Ü–∏–∏
                    detections = []
                
                # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ FPS
                fps = self.fps_counter.update()
                
                # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                frame = self.draw_stats(frame, fps)
                
                # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–∞–¥—Ä–∞ –¥–ª—è —Å–∫—Ä–∏–Ω—à–æ—Ç–∞
                self.last_frame = frame.copy()
                
                # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
                cv2.imshow(window_name, frame)
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∞–≤–∏—à
                key = cv2.waitKey(1) & 0xFF
                if not self.handle_key(key):
                    break
        
        except KeyboardInterrupt:
            print("\n[INFO] –ü—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (Ctrl+C)")
        
        finally:
            self.cleanup()
    
    def cleanup(self):
        """–û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        print("[INFO] –û—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤...")
        
        if self.cap is not None:
            self.cap.release()
        
        cv2.destroyAllWindows()
        print("[INFO] ‚úÖ –ì–æ—Ç–æ–≤–æ. –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")


def parse_arguments():
    """–ü–∞—Ä—Å–∏–Ω–≥ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏"""
    parser = argparse.ArgumentParser(
        description="Object Detector - –î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ —Å –≤–µ–±-–∫–∞–º–µ—Ä—ã",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
–ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
  python main.py                    # –ó–∞–ø—É—Å–∫ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
  python main.py --fast             # –ë—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º (–Ω–∏–∑–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ)
  python main.py --accurate         # –¢–æ—á–Ω—ã–π —Ä–µ–∂–∏–º (–≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ)
  python main.py --config my.yaml   # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–≤–æ–π –∫–æ–Ω—Ñ–∏–≥
        """
    )
    
    parser.add_argument('--config', '-c', type=str, default='config.yaml',
                       help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: config.yaml)')
    
    mode_group = parser.add_mutually_exclusive_group()
    mode_group.add_argument('--fast', action='store_true',
                           help='–ë—ã—Å—Ç—Ä—ã–π —Ä–µ–∂–∏–º (320x240, –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥)')
    mode_group.add_argument('--balanced', action='store_true',
                           help='–°–±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ä–µ–∂–∏–º (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)')
    mode_group.add_argument('--accurate', action='store_true',
                           help='–¢–æ—á–Ω—ã–π —Ä–µ–∂–∏–º (1280x720, –≤—ã—Å–æ–∫–∏–π –ø–æ—Ä–æ–≥)')
    
    parser.add_argument('--camera', '-cam', type=int, default=None,
                       help='–ò–Ω–¥–µ–∫—Å –∫–∞–º–µ—Ä—ã (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: 0)')
    
    parser.add_argument('--confidence', '-conf', type=float, default=None,
                       help='–ü–æ—Ä–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ (0.0-1.0)')
    
    return parser.parse_args()


def main():
    """–¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞"""
    args = parse_arguments()
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∂–∏–º–∞
    mode = None
    if args.fast:
        mode = 'fast'
    elif args.accurate:
        mode = 'accurate'
    elif args.balanced:
        mode = 'balanced'
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    config = Config(args.config, mode)
    
    # –ü–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–∏
    if args.camera is not None:
        config.config['camera']['index'] = args.camera
    
    if args.confidence is not None:
        config.config['detection']['confidence'] = args.confidence
    
    # –ó–∞–ø—É—Å–∫ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
    detector = ObjectDetector(config)
    detector.run()


if __name__ == "__main__":
    main()